{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab10d6b1-09d4-4b35-b837-019fd9b87e4f",
   "metadata": {},
   "source": [
    "# 🔥🐍 PySpark in Python: Step 1️⃣ - Installation and Setup in Jupyter Notebook 🚀  \n",
    "\n",
    "## ❓ Want to learn PySpark but don’t want to pay for expensive tools?  \n",
    "🙃 Good news! You can install and configure it in Jupyter Notebook for free.  \n",
    "\n",
    "## 👉 Solution  \n",
    "We’ll use `findspark` to make PySpark work locally without complex configurations.  \n",
    "\n",
    "## 🔧 How does it work?  \n",
    "`findspark` allows us to import PySpark into a notebook without manually setting environment variables.  \n",
    "\n",
    "## 🔎 Why does it matter?  \n",
    "✔️ **Experiment with Big Data** on your PC at no cost.  \n",
    "✔️ Learn PySpark before moving to **AWS EMR** or **Databricks** clusters.  \n",
    "✔️ Perfect for quick testing and **agile development**.  \n",
    "\n",
    "## ⚠️ Limitations of running PySpark locally  \n",
    "🔹 Local PySpark doesn’t leverage distributed computing like a real cluster.  \n",
    "🔹 Performance is limited by your PC’s resources (CPU, RAM).  \n",
    "🔹 No horizontal scaling, which can cause bottlenecks with large datasets.  \n",
    "🔹 Some Spark optimizations, like advanced parallelization, don’t work the same way as in a distributed environment.  \n",
    "\n",
    "## ✨ Real-world example  \n",
    "Imagine analyzing massive **social media data** in Spark without relying on expensive infrastructure. With this setup, you can process tweets on your laptop before scaling.  \n",
    "\n",
    "## ⚙️ Business impact  \n",
    "📊 **Companies can test Machine Learning models in PySpark locally before investing in high-performance servers.**  \n",
    "\n",
    "## 📊 Code summary  \n",
    "1️⃣ Install `PySpark` and `findspark`.  \n",
    "2️⃣ Configure `findspark` to locate Spark.  \n",
    "3️⃣ Create a **Spark session** in **Jupyter Notebook**.  \n",
    "4️⃣ Test the setup by loading a **sample DataFrame**.  \n",
    "\n",
    "🔗 **GitHub repository:** [PySparkForAll - Step 1️⃣](https://github.com/jcombari/PySparkForAll/blob/main/20250320_Step%201%EF%B8%8F%E2%83%A3%20-%20Installation%20and%20Setup%20in%20Jupyter%20Notebook%20%F0%9F%9A%80.ipynb)  \n",
    "\n",
    "💭 **Have you used PySpark before? Share your experience or ask any questions.**  \n",
    "\n",
    "🔑 #PySpark #BigData #MachineLearning #Python #JupyterNotebook #DataScience  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 🔥🐍 PySpark en Python: Paso 1️⃣ - Instalación y Configuración en Jupyter Notebook 🚀  \n",
    "\n",
    "## ❓ ¿Quieres aprender PySpark pero no quieres pagar herramientas costosas?  \n",
    "🙃 ¡Buenas noticias! Puedes instalarlo y configurarlo en Jupyter Notebook sin gastar nada.  \n",
    "\n",
    "## 👉 Solución  \n",
    "Usaremos `findspark` para que PySpark funcione en local y sin configuraciones complicadas.  \n",
    "\n",
    "## 🔧 ¿Cómo funciona?  \n",
    "`findspark` nos permite importar PySpark en un notebook sin necesidad de configurar variables de entorno manualmente.  \n",
    "\n",
    "## 🔎 ¿Por qué importa?  \n",
    "✔️ Permite experimentar con **Big Data** en tu PC sin costos adicionales.  \n",
    "✔️ Facilita el aprendizaje antes de pasar a clusters como **AWS EMR** o **Databricks**.  \n",
    "✔️ Ideal para pruebas rápidas y desarrollo ágil.  \n",
    "\n",
    "## ⚠️ Limitaciones del uso en modo local  \n",
    "🔹 PySpark en local no aprovecha la computación distribuida como en un clúster real.  \n",
    "🔹 El rendimiento está limitado por los recursos de tu PC (CPU, RAM).  \n",
    "🔹 No permite el escalado horizontal, lo que puede generar cuellos de botella en grandes volúmenes de datos.  \n",
    "🔹 Algunas optimizaciones de Spark, como la paralelización avanzada, no funcionan de la misma manera que en un entorno distribuido.  \n",
    "\n",
    "## ✨ Ejemplo real  \n",
    "Imagina que quieres analizar grandes volúmenes de datos de redes sociales en Spark sin depender de infraestructuras pagas. Con esta configuración, puedes procesar tweets en tu laptop antes de escalar.  \n",
    "\n",
    "## ⚙️ Impacto en el negocio  \n",
    "📊 **Las empresas pueden probar modelos de Machine Learning en PySpark localmente antes de invertir en servidores de alto rendimiento.**  \n",
    "\n",
    "## 📊 Resumen del código  \n",
    "1️⃣ Instalamos `PySpark` y `findspark`.  \n",
    "2️⃣ Configuramos `findspark` para localizar Spark.  \n",
    "3️⃣ Creamos una sesión de Spark en **Jupyter Notebook**.  \n",
    "4️⃣ Probamos que funciona cargando un **DataFrame de ejemplo**.  \n",
    "\n",
    "🔗 **Repositorio en GitHub:** [PySparkForAll - Paso 1️⃣](https://github.com/jcombari/PySparkForAll/blob/main/20250320_Step%201%EF%B8%8F%E2%83%A3%20-%20Installation%20and%20Setup%20in%20Jupyter%20Notebook%20%F0%9F%9A%80.ipynb)  \n",
    "\n",
    "💭 **¿Has usado PySpark antes? Comenta tu experiencia o pregunta lo que necesites.**  \n",
    "\n",
    "🔑 #PySpark #BigData #MachineLearning #Python #JupyterNotebook #DataScience  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
